version: "3.5"

services:
  namenode:
    image: tornermarton/hadoop
    command: hdfs namenode
    user: hdfs:hadoop
    container_name: nn.example
    hostname: nn.example.com
    restart: unless-stopped
    ports:
      - "9871:9871"
      - "50470:50470"
    env_file:
      - .env
    volumes:
      - hdfs-nn:/data/0/nn
      - ./keystore/hdfs.jks:/hdfs.jks
      - ./keytab:/etc/security/keytab
      - ./krb5.conf:/etc/krb5.conf
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

#  journalnode:
#    image: tornermarton/hadoop
#    command: hdfs journalnode
#    user: hdfs:hadoop
#    container_name: jn.example
#    hostname: jn.example.com
#    restart: unless-stopped
#    ports:
#      - "8481:8481"
#    depends_on:
#      - namenode
#    env_file:
#      - .env
#    volumes:
#      - hdfs-jn:/data/0/jn
#      - ./keystore/hdfs.jks:/hdfs.jks
#      - ./keytab:/etc/security/keytab
#      - ./krb5.conf:/etc/krb5.conf
#    logging:
#      driver: "json-file"
#      options:
#        max-size: "200k"
#        max-file: "10"

  datanode01:
    image: tornermarton/hadoop
    command: hdfs datanode
    user: hdfs:hadoop
    container_name: dn01.example
    hostname: dn01.example.com
    restart: unless-stopped
    depends_on:
      - namenode
    env_file:
      - .env
    volumes:
      - hdfs-dn:/data/0/dn
      - ./keystore/hdfs.jks:/hdfs.jks
      - ./keytab:/etc/security/keytab
      - ./krb5.conf:/etc/krb5.conf
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  resourcemanager:
    image: tornermarton/hadoop
    command: yarn resourcemanager
    user: yarn:hadoop
    container_name: rm.example
    hostname: rm.example.com
    restart: unless-stopped
    ports:
      - "8090:8090"
    depends_on:
      - namenode
    env_file:
      - .env
    volumes:
      - ./keystore/hdfs.jks:/hdfs.jks
      - ./keytab:/etc/security/keytab
      - ./krb5.conf:/etc/krb5.conf
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  nodemanager01:
    image: tornermarton/hadoop
    command: yarn nodemanager
    user: yarn:hadoop
    container_name: nm01.example
    hostname: nm01.example.com
    restart: unless-stopped
    ports:
      - "8044:8044"
    depends_on:
      - namenode
      - resourcemanager
    env_file:
      - .env
    volumes:
      - ./keystore/hdfs.jks:/hdfs.jks
      - ./keytab:/etc/security/keytab
      - ./krb5.conf:/etc/krb5.conf
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  historyserver:
    image: tornermarton/hadoop
    command: yarn historyserver
    user: mapred:hadoop
    container_name: jhs.example
    hostname: jhs.example.com
    restart: unless-stopped
    ports:
      - "8190:8190"
    depends_on:
      - namenode
      - resourcemanager
    env_file:
      - .env
    volumes:
      - hdfs-history:/hadoop/yarn/timeline
      - ./keystore/hdfs.jks:/hdfs.jks
      - ./keytab:/etc/security/keytab
      - ./krb5.conf:/etc/krb5.conf
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

#  spark-historyserver:
#    image: tornermarton/hadoop
#    command: start-history-server.sh
#    user: spark:hadoop
#    restart: unless-stopped
#    ports:
#    - "18080:18080"
#    depends_on:
#      - namenode
#      - datanode
#      - resourcemanager
#    env_file:
#      - .env
#    environment:
#      SPARK_NO_DAEMONIZE: "true"
#    logging:
#      driver: "json-file"
#      options:
#        max-size: "200k"
#        max-file: "10"

  gateway:
    image: tornermarton/hadoop-gateway
    command: tail -f /dev/null
    container_name: gw.example
    hostname: gw.example.com
    restart: unless-stopped
    depends_on:
      - namenode
    env_file:
      - .env
    volumes:
      - ./keytab:/etc/security/keytab
      - ./krb5.conf:/etc/krb5.conf
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

volumes:
  hdfs-nn:
  hdfs-dn:
  hdfs-jn:
  hdfs-history:

networks:
  default:
    name: com
